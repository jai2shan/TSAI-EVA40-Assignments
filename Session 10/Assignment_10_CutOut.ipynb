{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment_8_Trial_2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jai2shan/TSAI-EVA40-Assignments/blob/master/Session%2010/Assignment_10_CutOut.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JrzTU8SwHKsw",
        "colab_type": "code",
        "outputId": "3141678a-5b1e-452f-ca44-0652d869d690",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!pip install asgnmt9-0.0.6-py3-none-any.whl\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: asgnmt9==0.0.6 from file:///content/asgnmt9-0.0.6-py3-none-any.whl in /usr/local/lib/python3.6/dist-packages (0.0.6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7N06n-UEv_Ni",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class Cutout:\n",
        "    \"\"\"Randomly mask out one or more patches from an image.\n",
        "    Args:\n",
        "        n_holes (int): Number of patches to cut out of each image.\n",
        "        length (int): The length (in pixels) of each square patch.\n",
        "    \"\"\"\n",
        "    def __init__(self, prob, n_holes, length):\n",
        "        self.n_holes = n_holes\n",
        "        self.length = length\n",
        "        self.prob = prob\n",
        "\n",
        "    def __call__(self, img):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            img (Tensor): Tensor image of size (C, H, W).\n",
        "        Returns:\n",
        "            Tensor: Image with n_holes of dimension length x length cut out of it.\n",
        "        \"\"\"\n",
        "        h = img.size(1)\n",
        "        w = img.size(2)\n",
        "\n",
        "        if np.random.random()>self.prob:\n",
        "          return img\n",
        "        else:\n",
        "          mask = np.ones((h, w), np.float32)\n",
        "\n",
        "          for n in range(self.n_holes):\n",
        "              y = np.random.randint(h)\n",
        "              x = np.random.randint(w)\n",
        "\n",
        "              y1 = np.clip(y - self.length // 2, 0, h)\n",
        "              y2 = np.clip(y + self.length // 2, 0, h)\n",
        "              x1 = np.clip(x - self.length // 2, 0, w)\n",
        "              x2 = np.clip(x + self.length // 2, 0, w)\n",
        "\n",
        "              mask[y1: y2, x1: x2] = 0.\n",
        "\n",
        "          mask = torch.from_numpy(mask)\n",
        "          mask = mask.expand_as(img)\n",
        "          img = img * mask\n",
        "\n",
        "          return img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B4uVoJSzZ8V6",
        "colab_type": "text"
      },
      "source": [
        "## Updates in this trial\n",
        "\n",
        "> Changing the learning rate to 0.1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V4NWH6paHYSf",
        "colab_type": "code",
        "outputId": "3443e8fe-1565-4e06-fc6f-72d6dbf32631",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from torchvision import transforms\n",
        "from asgnmt9.DataLoader import cifar_data_loader,View_images\n",
        "\n",
        "transform_params = dict()\n",
        "transform_params['train'] = transforms.Compose([\n",
        "                                       transforms.RandomRotation(10),\n",
        "                                       transforms.RandomHorizontalFlip(),  \n",
        "                                       transforms.RandomAffine(0,shear=10,scale=(0.8,1.2)),  \n",
        "                                       transforms.ColorJitter(brightness=0.2,contrast=0.2,saturation=0.2),\n",
        "                                       transforms.ToTensor(),\n",
        "                                       Cutout(n_holes=1, length=16,prob = 0.3),\n",
        "                                       transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))])\n",
        "\n",
        "transform_params['test'] = transforms.Compose([\n",
        "                                       transforms.ToTensor(),\n",
        "                                       transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))])\n",
        "\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "trainloader,testloader = cifar_data_loader(transform_params,BatchSize=250)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PfxWk4x2IFs1",
        "colab_type": "code",
        "outputId": "3af1b5db-f2a2-445e-8c3a-35758952a8bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import torch\n",
        "\n",
        "from torchsummary import summary\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "print(device)\n",
        "\n",
        "from asgnmt9.resnet import ResNet18\n",
        "net = ResNet18().to(device)\n",
        "summary(net, input_size=(3,32,32))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 32, 32]           1,728\n",
            "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
            "            Conv2d-3           [-1, 64, 32, 32]          36,864\n",
            "       BatchNorm2d-4           [-1, 64, 32, 32]             128\n",
            "            Conv2d-5           [-1, 64, 32, 32]          36,864\n",
            "       BatchNorm2d-6           [-1, 64, 32, 32]             128\n",
            "        BasicBlock-7           [-1, 64, 32, 32]               0\n",
            "            Conv2d-8           [-1, 64, 32, 32]          36,864\n",
            "       BatchNorm2d-9           [-1, 64, 32, 32]             128\n",
            "           Conv2d-10           [-1, 64, 32, 32]          36,864\n",
            "      BatchNorm2d-11           [-1, 64, 32, 32]             128\n",
            "       BasicBlock-12           [-1, 64, 32, 32]               0\n",
            "           Conv2d-13          [-1, 128, 16, 16]          73,728\n",
            "      BatchNorm2d-14          [-1, 128, 16, 16]             256\n",
            "           Conv2d-15          [-1, 128, 16, 16]         147,456\n",
            "      BatchNorm2d-16          [-1, 128, 16, 16]             256\n",
            "           Conv2d-17          [-1, 128, 16, 16]           8,192\n",
            "      BatchNorm2d-18          [-1, 128, 16, 16]             256\n",
            "       BasicBlock-19          [-1, 128, 16, 16]               0\n",
            "           Conv2d-20          [-1, 128, 16, 16]         147,456\n",
            "      BatchNorm2d-21          [-1, 128, 16, 16]             256\n",
            "           Conv2d-22          [-1, 128, 16, 16]         147,456\n",
            "      BatchNorm2d-23          [-1, 128, 16, 16]             256\n",
            "       BasicBlock-24          [-1, 128, 16, 16]               0\n",
            "           Conv2d-25            [-1, 256, 8, 8]         294,912\n",
            "      BatchNorm2d-26            [-1, 256, 8, 8]             512\n",
            "           Conv2d-27            [-1, 256, 8, 8]         589,824\n",
            "      BatchNorm2d-28            [-1, 256, 8, 8]             512\n",
            "           Conv2d-29            [-1, 256, 8, 8]          32,768\n",
            "      BatchNorm2d-30            [-1, 256, 8, 8]             512\n",
            "       BasicBlock-31            [-1, 256, 8, 8]               0\n",
            "           Conv2d-32            [-1, 256, 8, 8]         589,824\n",
            "      BatchNorm2d-33            [-1, 256, 8, 8]             512\n",
            "           Conv2d-34            [-1, 256, 8, 8]         589,824\n",
            "      BatchNorm2d-35            [-1, 256, 8, 8]             512\n",
            "       BasicBlock-36            [-1, 256, 8, 8]               0\n",
            "           Conv2d-37            [-1, 512, 4, 4]       1,179,648\n",
            "      BatchNorm2d-38            [-1, 512, 4, 4]           1,024\n",
            "           Conv2d-39            [-1, 512, 4, 4]       2,359,296\n",
            "      BatchNorm2d-40            [-1, 512, 4, 4]           1,024\n",
            "           Conv2d-41            [-1, 512, 4, 4]         131,072\n",
            "      BatchNorm2d-42            [-1, 512, 4, 4]           1,024\n",
            "       BasicBlock-43            [-1, 512, 4, 4]               0\n",
            "           Conv2d-44            [-1, 512, 4, 4]       2,359,296\n",
            "      BatchNorm2d-45            [-1, 512, 4, 4]           1,024\n",
            "           Conv2d-46            [-1, 512, 4, 4]       2,359,296\n",
            "      BatchNorm2d-47            [-1, 512, 4, 4]           1,024\n",
            "       BasicBlock-48            [-1, 512, 4, 4]               0\n",
            "           Linear-49                   [-1, 10]           5,130\n",
            "================================================================\n",
            "Total params: 11,173,962\n",
            "Trainable params: 11,173,962\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 11.25\n",
            "Params size (MB): 42.63\n",
            "Estimated Total Size (MB): 53.89\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GOv3gb8Xtwue",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "20wVazumHl-T",
        "colab_type": "code",
        "outputId": "c064eb10-0434-42a1-c909-d5bca1ffc85c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        }
      },
      "source": [
        "from asgnmt9.Training_Testing import TrainTest\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "\n",
        "tt = TrainTest()\n",
        "test_acc = 0\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.1, momentum=0.9,weight_decay = 0.00005)\n",
        "scheduler = StepLR(optimizer, step_size=30, gamma=0.1)\n",
        "\n",
        "for epoch in range(50):\n",
        "    print(\"EPOCH:\", epoch)\n",
        "    tt.train_(net, device, trainloader, optimizer, criterion, epoch,L1 = False)\n",
        "    scheduler.step()\n",
        "    acc = tt.test_(net, device, testloader)  \n",
        "    \n",
        "   \n",
        "print('Finished Training')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/200 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "EPOCH: 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=1.724996566772461 Batch_id=199 Accuracy=28.11: 100%|██████████| 200/200 [01:10<00:00,  2.84it/s]\n",
            "  0%|          | 0/200 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: -1.8843, Accuracy: 3997/10000 (39.97%)\n",
            "\n",
            "EPOCH: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=1.5533655881881714 Batch_id=199 Accuracy=42.00: 100%|██████████| 200/200 [01:10<00:00,  2.83it/s]\n",
            "  0%|          | 0/200 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: -2.3423, Accuracy: 4873/10000 (48.73%)\n",
            "\n",
            "EPOCH: 2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=1.396450400352478 Batch_id=199 Accuracy=50.04: 100%|██████████| 200/200 [01:10<00:00,  2.82it/s]\n",
            "  0%|          | 0/200 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: -3.2774, Accuracy: 5387/10000 (53.87%)\n",
            "\n",
            "EPOCH: 3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=1.1208031177520752 Batch_id=199 Accuracy=56.54: 100%|██████████| 200/200 [01:11<00:00,  2.82it/s]\n",
            "  0%|          | 0/200 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: -3.9604, Accuracy: 6206/10000 (62.06%)\n",
            "\n",
            "EPOCH: 4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.9842718243598938 Batch_id=199 Accuracy=61.27: 100%|██████████| 200/200 [01:11<00:00,  2.82it/s]\n",
            "  0%|          | 0/200 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: -4.4896, Accuracy: 6793/10000 (67.93%)\n",
            "\n",
            "EPOCH: 5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.879986047744751 Batch_id=199 Accuracy=65.35: 100%|██████████| 200/200 [01:11<00:00,  2.82it/s]\n",
            "  0%|          | 0/200 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: -5.0000, Accuracy: 7121/10000 (71.21%)\n",
            "\n",
            "EPOCH: 6\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.8834431767463684 Batch_id=199 Accuracy=67.85: 100%|██████████| 200/200 [01:11<00:00,  2.82it/s]\n",
            "  0%|          | 0/200 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: -5.6683, Accuracy: 7306/10000 (73.06%)\n",
            "\n",
            "EPOCH: 7\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.8720763325691223 Batch_id=175 Accuracy=70.97:  88%|████████▊ | 176/200 [01:02<00:08,  2.85it/s]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oMD8DtYFPrSc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from asgnmt9.ModelPerformance import *\n",
        "\n",
        "PlotTrainingGraphs(tt)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wvE2G-oej29z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Misclassification(testloader,net,classes,device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s1q8Q7iWP9qs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ViewModelPerformance(testloader,net,classes,device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9fxcy3EEVKzf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from asgnmt9.gradcam import GradCamDisplay\n",
        "import PIL\n",
        "img_name =['airplane.png','automobile.png','bird.png','cat.png','deer.png']\n",
        "\n",
        "pil_image = []\n",
        "for i,img in enumerate(img_name):\n",
        "   pil_image.append(PIL.Image.open(img))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XCxqYUKTWSy9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from asgnmt9.gradcam import *\n",
        "def GradCamDisplay(model,pil_image,classes,device):\n",
        "    normed_torch_img = []\n",
        "    torch_img_list = []\n",
        "\n",
        "    for i in pil_image:\n",
        "      torch_img = transforms.Compose([\n",
        "          transforms.Resize((32, 32)),\n",
        "          transforms.ToTensor()])(i).to(device)\n",
        "      torch_img_list.append(torch_img)\n",
        "      normed_torch_img .append(transforms.Normalize([0.4914, 0.4822, 0.4465], [0.247, 0.243, 0.261])(torch_img)[None])\n",
        "\n",
        "    def imshow(img,c = \"\" ):\n",
        "        #img = img / 2 + 0.5     # unnormalize\n",
        "        npimg = img.numpy()\n",
        "        fig = plt.figure(figsize=(10,10))\n",
        "        plt.imshow(np.transpose(npimg, (1, 2, 0)),interpolation='none')\n",
        "        plt.title(c)\n",
        "\n",
        "    for i,k in enumerate(normed_torch_img):\n",
        "      images1 = [torch_img_list[i].cpu()]\n",
        "      images2 =  [torch_img_list[i].cpu()]\n",
        "      b = copy.deepcopy(model.to(device))\n",
        "      output = model(normed_torch_img[i])\n",
        "      _, predicted = torch.max(output.data, 1)\n",
        "      #print(classes[int(predicted)])\n",
        "      layers =  [b.layer1,b.layer2,b.layer3,b.layer4]\n",
        "      \n",
        "      for j in layers:\n",
        "        g = GradCAM(b,j)\n",
        "        mask, _= g(normed_torch_img[i])\n",
        "        heatmap, result = visualize_cam(mask,torch_img_list[i] )\n",
        "        images1.extend([heatmap])\n",
        "        images2.extend([result])\n",
        "\n",
        "      grid_image = make_grid(images1+images2,nrow=5)\n",
        "      imshow(grid_image,c = classes[int(predicted)])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MUBrjJOIjQBw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import copy\n",
        "GradCamDisplay(net,pil_image,classes,device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZWGP6IuMsb-z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}